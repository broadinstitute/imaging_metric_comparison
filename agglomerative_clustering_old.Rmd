---
title: "replicateClusteringOld"
output: html_document
---

After Hit Selection the next step is to do a clustering depending on the phenotype of the compound.

- Summary of a compound is done by taking the average along the replicate. (selected in Markdown file: replicateCorrelation.Rmd)
- Calculate the correlation compound-compound. This can be used as a metric for clustering.
- 1-corr is a metric: usually use Agglomerative clustering (explore different linkage function)

## Data

The input contains only the high median correlation compounds.
The input data is a 3752 by 803 matrix.
There are 3752 different observations and 799 features (extracted with CellProfiler).
Each compound (938 different) has 4 replicates.


```{r setup, include=FALSE}
# all usefull libraries
library(magrittr)
library(dplyr)
library(ggplot2)
library(reshape2)
library(foreach)
library(doMC)
library(stringr)
library(tidyverse)
```

## parameters
```{r parameters}
numClust <- 300
#set.seed(42)
```

```{r import new data, message=FALSE}
pf <- readRDS(file.path("..", "..", "input", "BBBC022_2013", "old", "Hit_jaccard_50n_6225.rds"))
```

## Summary of the compound

```{r compound summary}
# find the different compounds
IDs <- distinct(pf$data, Image_Metadata_BROAD_ID)
dim(IDs)

# mapping IDs-Compounds: give access to the compound knowing the IDs
map.names <-
  pf$data %>%
  dplyr::select(one_of(c("Image_Metadata_BROAD_ID","Image_Metadata_SOURCE_COMPOUND_NAME"))) %>%
  unique %>%
  mutate_if(is.factor, as.character) %>%
  as.data.frame()
rownames(map.names) <- map.names$Image_Metadata_BROAD_ID


# average along replicate (keep only id and variables)
sum.comp <- 
  pf$data %>% 
  group_by(Image_Metadata_BROAD_ID) %>% 
  summarise_each(funs(mean(., na.rm=TRUE)), -c(Image_Metadata_SOURCE_COMPOUND_NAME, Well, Plate)) %>%
  mutate_if(is.factor, as.character)

# add column of compound and convert tu uppercase (because some compounds same name but in lower/upper case)
sum.comp %<>%
  dplyr::left_join(., map.names, by = "Image_Metadata_BROAD_ID") %>% 
  mutate_if(is.character, funs(toupper))
dim(sum.comp)

# keep only one componment (first one)
sum.comp %<>%
  group_by(Image_Metadata_SOURCE_COMPOUND_NAME) %>%
  slice(1) %>%
  ungroup
dim(sum.comp)

```

## Agglomerative clusering

```{r clustering}
# correlation compound-compound
cor.comp <-
  sum.comp[, pf$feat_cols] %>% 
  as.matrix() %>%
  t() %>%
  cor()

# metric for clustering: 1 - correlation
met.clust <- as.dist(1 - cor.comp)

# Agglomerative clustering using a linkage function
clust.res <- hclust(met.clust, method = "average")

plot(clust.res, cex = 0.01, hang = -1)
```

## stability around different threshold
only use stability to find the threshold when using h and not k (k is the number of cluster)
```{r stability, eval=FALSE}
# Interval of threshold to find the optimal one
height.interval <- seq(from = 0.2, to = 0.8, by = 0.01)
epsilon <- 0.01

#stability of each threshold
h.stability <- c()

for ( h in height.interval ){
  # look at cluster around h (h + epsilon and h - epsilon) and find the stability around it
  h.minus <- cutree(clust.res, h = h - epsilon)
  h.plus <- cutree(clust.res, h = h + epsilon)
  
  h.stability <- c(h.stability, sum(h.minus == h.plus)/length(h.plus))
}

mav <- function(x,n=5){stats::filter(x, rep(1/n,n), sides=2)}

h.stability.mav <- mav(h.stability,n = 4)
plot(height.interval, 
     h.stability,
     type = "b",
     col = "blue",
     xlab = "Height threshold",
     ylab = "Stability")
lines(height.interval,
      h.stability.mav,
      type = "l",
      col = "red")

# find the threshold where the cut will be applied
thres <- height.interval[min(which(h.stability >= 0.97))]
abline(v=thres)
legend("bottomright", 
       c("Stability", "Moving average", "Threshold"),
       lty=c(1,1,1), 
       col=c("blue","red", "black"))
```

## Dendrogram of the cluters of the compounds
Plotting the dendrogram according to the threshold

```{r dendrogram}
plot(clust.res, cex = 0.01, hang = -1)
rect.hclust(clust.res, k = numClust, border = "red")

```


## Extract names for each clusters

```{r clusters compounds}
# find the cluster for each compound
sum.comp.clust <- 
  sum.comp %>%
  mutate(cluster = cutree(clust.res, k = numClust))

```

## MOA data

```{r import MOAs}
# import MOAs data
moa <- 
  read.csv("../../input/BBBC022_2013/MOAs.csv", na.strings = c("", "NA")) %>%
  mutate_if(is.factor, as.character) %>%
  plyr::rename(c("Name" = "Image_Metadata_SOURCE_COMPOUND_NAME")) 
# compounds name to upper case
moa$Image_Metadata_SOURCE_COMPOUND_NAME <-
  lapply(moa[, "Image_Metadata_SOURCE_COMPOUND_NAME"], stringr::str_to_upper) %>%
  unlist
moa %<>% 
  group_by(Image_Metadata_SOURCE_COMPOUND_NAME) %>%
  slice(1) %>%
  ungroup


# join moa data to cluster data 
final.sum.comp.clust <-
  sum.comp.clust %>%
  select(Image_Metadata_SOURCE_COMPOUND_NAME, cluster) %>%
  dplyr::left_join(., moa, by = "Image_Metadata_SOURCE_COMPOUND_NAME") 
dim(final.sum.comp.clust)
# remove row where MOA is NA
final.sum.comp.clust.moa <-
  final.sum.comp.clust[complete.cases(final.sum.comp.clust[,"MOA"]),]
dim(final.sum.comp.clust.moa)

# select only the MOA and the cluster column
df.clust.moa <-
  final.sum.comp.clust.moa %>% 
  select(cluster, MOA)
dim(df.clust.moa)


#knitr::kable(final.sum.comp.clust.moa, caption = "Clustering of components with associated MOAs")

```

Separate the MOAs if there are multiple for one compound.

```{r moa compound}
start.time <- Sys.time()

for (i in 1:dim(df.clust.moa)[1]){
  # if there are more than 1 moa associated
  if (str_detect(df.clust.moa$MOA[i], ",")){
    t1 <- str_trim(str_split(df.clust.moa$MOA[i], ",")[[1]])
    df.clust.moa$MOA[i] <- t1[1]
    new.row <- df.clust.moa[i,]
    new.row$MOA <- t1[2]
    df.clust.moa <- rbind(df.clust.moa, new.row)
  }
  
}

dim.before <- dim(df.clust.moa)[1]

# remove compound that are clustered on their own!
df.clust.moa %<>%
  group_by(cluster) %>% 
  mutate(n = n()) %>% # count number of element in each cluster
  ungroup(cluster) %>%
  filter(n > 1) # remove element that have only themself in their cluster

dim.after <- dim(df.clust.moa)[1]
num.singleton <- dim.before - dim.after
threshold <- .05*dim(IDs)[1]
message(paste('number of singletons: ', num.singleton, ' threshold: ', threshold))

if(num.singleton > threshold){
  message(paste('number of singleton too big! '))
}

dim(df.clust.moa)
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken

```

Solve the problem of the multiple moa for same compound
```{r moa}
# remove row where MOA is NA
moa.ext <-
  moa[complete.cases(moa[,"MOA"]),]
dim(moa.ext)

# duplicate row where multiple moas for same compound
for (i in 1:dim(moa.ext)[1]){
  # if there are more than 1 moa associated
  if (str_detect(moa.ext$MOA[i], ",")){
    t1 <- str_trim(str_split(moa.ext$MOA[i], ",")[[1]])
    moa.ext$MOA[i] <- t1[1]
    new.row <- moa.ext[i,]
    new.row$MOA <- t1[2]
    moa.ext <- rbind(moa.ext, new.row)
  }
  
}
dim(moa.ext)

```


## Fisher's exact test

4 different classes created comparing all pairs of data:

- same MOA and same cluster

- same MOA but different cluster

- different MOA but same cluster

- different MOA and different cluster

```{r Fishers exact test}
# create matrix of comparison
moa.mat <- outer(df.clust.moa$MOA, df.clust.moa$MOA, function(x, y) x==y)
clust.mat <- outer(df.clust.moa$cluster, df.clust.moa$cluster, function(x, y) x==y)
# transform into a vector with the indices and combine both moa and cluster information together, keep only the upper triangle of the matrix 
tmp1 <- melt(moa.mat) %>%
  plyr::rename(c("value" = "same.moa"))
tmp2 <- melt(clust.mat)
tmp1$same.clust <- tmp2$value
tmp1 %<>% filter(Var1 < Var2)

# contingency table
contingency.table <- 
  tmp1 %>%
  group_by(same.moa, same.clust) %>%
  summarise(cnt = n()) %>%
  xtabs(cnt ~ same.moa+same.clust, data = .)
contingency.mat <-
  matrix(c(contingency.table[2,2], contingency.table[2,1], contingency.table[1,2], contingency.table[1,1]), 
         nrow = 2, 
         ncol = 2, 
         byrow = TRUE)

contingency.table

# fisher test
fisher.test(contingency.mat, alternative = "greater")

```


## Results

We expect an odds ratio > 1, which means that if we have the same MOA, there is a higher chance to capture the same cluster.
Moreover we can see that a p-value smaller than 0.05 means that we reject H0.

Table of the odds ratio for different metric when hit selecting

note: fs = feature selection, k is the number of cluster, in () is the pvalue

|  Method   | Pearson            | Pearson with fs    | Jaccard            | Jaccard with fs    |
| --------- | ------------------ | ------------------ | ------------------ | ------------------ | 
| k = 10    | 1.7464 (< 2.2e-16) | 1.3458 (3.423e-06) | 1.9353 (< 2.2e-16) | 1.3907 (1.596e-07) |
| k = 20    | 2.1182 (< 2.2e-16) | 2.1693 (< 2.2e-16) | 1.8157 (< 2.2e-16) | 2.0729 (< 2.2e-16) |
| k = 30    | 2.0963 (< 2.2e-16) | **2.4312** (< 2.2e-16) | 1.8492 (< 2.2e-16) | **2.3715** (< 2.2e-16) |
| k = 40    | **2.3945** (< 2.2e-16) | 2.0285 (< 2.2e-16) | 1.8243 (< 2.2e-16) | 1.7745 (3.958e-14) |
| k = 50    | 1.6212 (1.245e-09) | 1.5711 (7.347e-09) | 1.9550 (< 2.2e-16) | 1.7879 (2.299e-14) |
| k = 60    | 1.5293 (1.498e-07) | 1.6907 (4.618e-11) | 1.9930 (< 2.2e-16) | 1.4759 (6.919e-07) |
| k = 70    | 1.5307 (1.418e-07) | 1.7688 (7.66e-12)  | **2.5029** (< 2.2e-16) | 1.3822 (4.065e-05) |
| k = 80    | 1.6172 (1.121e-08) | 1.7775 (5.26e-12)  | 2.1852 (< 2.2e-16) | 1.4949 (1.555e-06) |
| k = 90    | 1.6206 (1.047e-08) | 1.4831 (4.81e-06)  | 2.1911 (< 2.2e-16) | 1.5914 (1.093e-07) |
| k = 100   | 1.6086 (1.914e-08) | 1.6987 (9.644e-09) | 2.1982 (< 2.2e-16) | 1.6171 (5.402e-08) |


Plot of the odds ratio in function of the number of clusters (k) for 4 differents metric of hit selection:

```{r result plot, echo=FALSE}

value <- c(1.7464, 2.1182, 2.0963, 2.3945, 1.6212, 1.5293, 1.5307, 1.6172, 1.6206, 1.6086,
           1.3458, 2.1693, 2.4312, 2.0285, 1.5711, 1.6907, 1.7688, 1.7775, 1.4831, 1.6987,
           1.9353, 1.8157, 1.8492, 1.8243, 1.9550, 1.9930, 2.5029, 2.1852, 2.1911, 2.1982,
           1.3907, 2.0729, 2.3715, 1.7745, 1.7879, 1.4759, 1.3822, 1.4949, 1.5914, 1.6171)

test <- data.frame(k = rep(seq(from = 10, to = 100, by = 10), 4), 
                   val = value, 
                   method = rep(c("Pearson", "Pearson with feat. sel", "Jaccard", "Jaccard with feat. sel"), each = 10))

ggplot(data = test, aes(x=k, y=val)) + 
  geom_line(aes(colour=method)) + 
  labs(y = "odds ratio")

```


## Summary of moa
In each same MOA-same Cluster pair, count the number of time that a same MOA appears in a same cluster.

```{r summary moa}
final.sum <-
  df.clust.moa %>%
  group_by(cluster,MOA) %>%
  tally(sort = TRUE)

final <-
  moa.ext %>% 
  dplyr::select(MOA, Image_Metadata_SOURCE_COMPOUND_NAME) %>% 
  dplyr::group_by(MOA) %>%
  dplyr::summarise(n.cmpd = n()) %>% 
  dplyr::right_join(., final.sum, by = "MOA") %>% 
  #dplyr::filter(nn > 1) %>% #remove column where just one moa (meaning no pairs)
  dplyr::mutate(contribute = nn/n.cmpd)
#final.sum  

knitr::kable(final, caption = "Number of same MOAs in a same cluster compared to the number of total compounds for a specific MOA ")

```
