---
title: "Clustering Replicates"
output: html_document
---

After Hit Selection the next step is to do a clustering depending on the phenotype of the compound.

- Summary of a compound is done by taking the average along the replicate. (selected in Markdown file: replicateCorrelation.Rmd)
- Calculate the correlation compound-compound. This can be used as a metric for clustering.
- 1-corr is a metric: usually use Agglomerative clustering (explore different linkage function)

## Data

The input contains only the high median correlation compounds.
The input data is a 3752 by 803 matrix.
There are 3752 different observations and 799 features (extracted with CellProfiler).
Each compound (938 different) has 4 replicates.


```{r setup, include=FALSE}
# all usefull libraries
library(magrittr)
library(dplyr)
library(ggplot2)
library(reshape2)
library(foreach)
library(doMC)
library(stringr)
library(tidyverse)
```

```{r import data with feature selection, message=FALSE}
profiles <- 
  readr::read_csv(file.path("..", "..", "input", "BBBC022_2013", "BBBC022_2013_feat_sel_hit_sel_pearson.csv")) # 7680x(nfeat+metadata)

variables <-
  names(profiles) %>% str_subset("^Cells_|^Cytoplasm_|^Nuclei_") # nfeat

metadata <-
  names(profiles) %>% str_subset("^Metadata_") # metadata
```

## Summary of the compound

Do the average along replicates.

```{r compound summary}
# find the different compounds
IDs <- distinct(profiles, Metadata_broad_sample)
dim(IDs)

# mapping IDs-Compounds: give access to the compound knowing the IDs
map.names <-
  profiles %>%
  dplyr::select(one_of(c("Metadata_broad_sample","Metadata_compound_name"))) %>%
  unique %>%
  mutate_if(is.factor, as.character) %>%
  as.data.frame()
rownames(map.names) <- map.names$Metadata_broad_sample


# average along replicate (keep only id and variables)
sum.comp <-
  cbind(profiles[,"Metadata_broad_sample"], profiles[,variables]) %>%
  group_by(Metadata_broad_sample) %>%
  summarise_each(funs(mean(., na.rm=TRUE)))

# add column of compound and convert tu uppercase (because some compounds same name but in lower/upper case)
sum.comp %<>%
  dplyr::left_join(., map.names, by = "Metadata_broad_sample") %>% 
  mutate_if(is.character, funs(toupper))
dim(sum.comp)

# keep only one componment (first one)
sum.comp %<>%
  group_by(Metadata_compound_name) %>%
  slice(1) %>%
  ungroup
dim(sum.comp)

```


```{r compound summary, eval=FALSE}
# find the different compounds
IDs <- distinct(pf$data, Image_Metadata_BROAD_ID)
dim(IDs)

# mapping IDs-Compounds: give access to the compound knowing the IDs
map.names <- pf$data %>% dplyr::select(one_of(c("Image_Metadata_BROAD_ID","Image_Metadata_SOURCE_COMPOUND_NAME"))) %>% unique %>% mutate_if(is.factor, as.character)
rownames(map.names) <- map.names$Image_Metadata_BROAD_ID


# average along replicate
sum.comp <- pf$data %>% group_by(Image_Metadata_BROAD_ID) %>% summarise_each(funs(mean(., na.rm=TRUE)), -c(Image_Metadata_SOURCE_COMPOUND_NAME, Well, Plate)) %>% mutate_if(is.factor, as.character)

# add column of compound and convert tu uppercase (because some compounds same name but in lower/upper case)
sum.comp <- dplyr::left_join(sum.comp, map.names, by = "Image_Metadata_BROAD_ID") %>% mutate_if(is.character, funs(toupper))

dim(sum.comp)

# keep only one componment (first one)
sum.comp <- sum.comp %>% group_by(Image_Metadata_SOURCE_COMPOUND_NAME) %>% slice(1) %>% ungroup

dim(sum.comp)

```

## Agglomerative clusering

type of linkage function: "ward", "single", "complete", "average", "mcquitty", "median" or "centroid"
Calculate the correlation compound to compound and as a distance metric use 1 - correlation.
dist = 2 -> corr = -1
dist = 1 -> corr = 0
dist = 0 -> corr = 1
Use the agglomerative clustering with the average linkage function.

```{r clustering}
# correlation compound-compound
cor.comp <-
  sum.comp[,variables] %>% 
  as.matrix() %>%
  t() %>%
  cor()

# metric for clustering: 1 - correlation
met.clust <- as.dist(1 - cor.comp)

# Agglomerative clustering using a linkage function
clust.res <- hclust(met.clust, method = "average")

plot(clust.res, cex = 0.01, hang = -1)
```

```{r other dendrogram, include=FALSE, eval=FALSE}
clusterCut <- cutree(clust.res, k=10)

plot(clust.res, cex = 0.01)
rect.hclust(clust.res, k=10, border="red")

library(circlize)
library(dendextend)
dend <- as.dendrogram(clust.res)
dend <- dend %>% 
   color_branches(k=10) %>% 
   color_labels
par(mar = rep(0,4))
circlize_dendrogram(dend, labels = FALSE, dend_track_height = 0.9) 
```


## stability around different threshold
Visually on the dendrogram choose a range of threshold.
From 0.2 to 0.7 with a interval of 0.01. epsilon = 0.01.
The threshold was chosen visually. We want the lowest threshold with the maximal stability.
We can see that around 0.5 we reached a kind of saturation.

```{r stability}
# Interval of threshold to find the optimal one
height.interval <- seq(from = 0.2, to = 0.8, by = 0.01)
epsilon <- 0.01

#stability of each threshold
h.stability <- c()

for ( h in height.interval ){
  # look at cluster around h (h + epsilon and h - epsilon) and find the stability around it
  h.minus <- cutree(clust.res, h = h - epsilon)
  h.plus <- cutree(clust.res, h = h + epsilon)
  
  h.stability <- c(h.stability, sum(h.minus == h.plus)/length(h.plus))
}

mav <- function(x,n=5){stats::filter(x, rep(1/n,n), sides=2)}

h.stability.mav <- mav(h.stability,n = 4)
plot(height.interval, 
     h.stability,
     type = "b",
     col = "blue",
     xlab = "Height threshold",
     ylab = "Stability")
lines(height.interval,
      h.stability.mav,
      type = "l",
      col = "red")

# find the threshold where the cut will be applied
thres <- height.interval[min(which(h.stability >= 0.97))]
abline(v=thres)
legend("bottomright", 
       c("Stability", "Moving average", "Threshold"),
       lty=c(1,1,1), 
       col=c("blue","red", "black"))
```

## Dendrogram of the cluters of the compounds
Plotting the dendrogram according to the threshold

```{r dendrogram}
plot(clust.res, cex = 0.01, hang = -1)
rect.hclust(clust.res, h = thres, border = "red")

```


## Extract names for each clusters

```{r clusters}
# find the cluster for each compound
sum.comp.clust <- 
  sum.comp %>%
  mutate(cluster = cutree(clust.res, h = thres))

```

## MOA data

```{r import MOAs}
# import MOAs data
moa <- 
  read.csv("../../input/BBBC022_2013/MOAs.csv", na.strings = c("", "NA")) %>%
  mutate_if(is.factor, as.character) %>%
  plyr::rename(c("Name" = "Image_Metadata_SOURCE_COMPOUND_NAME")) 
# compounds name to upper case
moa$Image_Metadata_SOURCE_COMPOUND_NAME <-
  lapply(moa[, "Image_Metadata_SOURCE_COMPOUND_NAME"], stringr::str_to_upper) %>%
  unlist
moa %<>% 
  group_by(Image_Metadata_SOURCE_COMPOUND_NAME) %>%
  slice(1) %>%
  ungroup


# join moa data to cluster data 
final.sum.comp.clust <-
  sum.comp.clust %>%
  select(Image_Metadata_SOURCE_COMPOUND_NAME, cluster) %>%
  dplyr::left_join(., moa, by = "Image_Metadata_SOURCE_COMPOUND_NAME") %>%
  dim()
# remove row where MOA is NA
final.sum.comp.clust.moa <-
  final.sum.comp.clust[complete.cases(final.sum.comp.clust[,"MOA"]),] %>%
  dim()

# select only the MOA and the cluster column
df.clust.moa <-
  final.sum.comp.clust.moa %>% 
  select(cluster, MOA)


knitr::kable(final.sum.comp.clust.moa, caption = "Clustering of components with associated MOAs")

```

Separate the MOAs if there are multiple for one compound.

```{r moa}
start.time <- Sys.time()

for (i in 1:length(final.sum.comp.clust.moa)){
  # if there are more than 1 moa associated
  if (str_detect(final.sum.comp.clust.moa$MOA[i], ",")){
    t1 <- str_trim(str_split(final.sum.comp.clust.moa$MOA[i], ",")[[1]])
    final.sum.comp.clust.moa$MOA[i] <- t1[1]
    new.row <- final.sum.comp.clust.moa[i]
    new.row$MOA <- t1[2]
    final.sum.comp.clust.moa <- rbind(final.sum.comp.clust.moa, new.row)
  }
  
}

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken

```



## Fisher's exact test

4 different classes created comparing all pairs of data:

- same MOA and same cluster

- same MOA but different cluster

- different MOA but same cluster

- different MOA and different cluster

```{r Fishers exact test}
# create matrix of comparison
moa.mat <- outer(df.clust.moa$MOA, df.clust.moa$MOA, function(x, y) x==y)
clust.mat <- outer(df.clust.moa$cluster, df.clust.moa$cluster, function(x, y) x==y)
# transform into a vector with the indices and combine both moa and cluster information together, keep only the upper triangle of the matrix 
tmp1 <- melt(moa.mat) %>%
  plyr::rename(c("value" = "same.moa"))
tmp2 <- melt(clust.mat)
tmp1$same.clust <- tmp2$value
tmp1 %<>% filter(Var1 < Var2)

# contingency table
contingency.table <- 
  tmp1 %>%
  group_by(same.moa, same.clust) %>%
  summarise(cnt = n()) %>%
  xtabs(cnt ~ same.moa+same.clust, data = .)
contingency.mat <-
  matrix(c(contingency.table[2,2], contingency.table[2,1], contingency.table[1,2], contingency.table[1,1]), 
         nrow = 2, 
         ncol = 2, 
         byrow = TRUE)

contingency.table

# fisher test
fisher.test(contingency.mat, alternative = "greater")

```


## Results

We expect an odds ratio > 1, which means that if we have the same MOA, there is a higher chance to capture the same cluster.
Moreover we can see that a p-value smaller than 0.05 means that we reject H0.



