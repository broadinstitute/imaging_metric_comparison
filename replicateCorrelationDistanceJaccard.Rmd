---
title: "Replicate Distance Jaccard"
output:
  html_document: default
---
The goal is to do some Hit Selection. Selecting the compounds that have effects, that are showing a phenotype.
In order to do so, lets find the median replicate distance. 
The smaller the distance, the more correlated the replicates are.

The distance is defined following the Jaccard distance, which calculate the dissimilarities between sample sets.
The distance is defined as the mean of the distance between 4 sets. 

A) 50 top features of component x

B) 50 top features of component y

C) 50 bottom features of component x

D) 50 bottom features of component y

$dist(x,y) = \frac{dist_J(A,B) + dist_J(C,D)}{2}$

$dist_J(i,j) = \frac{|A \cup B| - |A \cap B|}{|A \cup B|}$ 

## Data

The input data is a 7680 by 803 matrix.
There are 7680 different observations and 799 features (extracted with CellProfiler).
Each compound (1600 different) has 4 replicates. The negative control has 1280 replicates.
20 plates with 384 wells in each plate.

```{r setup, include=FALSE, warning=FALSE}
# all usefull libraries
library(dplyr)
library(ggplot2)
```

```{r import data}
# import data
pf <- readRDS("../input/Pf_Gustafsdottir.rds")

# Remove the negative control from the data
pf$data <- filter(pf$data, !Image_Metadata_BROAD_ID %in% "")
```

## Parameters
```{r parameters}
# number of data to make the non replicate correlation
N <- 5000
set.seed(45)
```

## Separation of data

Separation is made according to the compound that was added.
Image_Metadata_BROAD_ID = gives the ID of the compound that was added.

```{r separation of data}
# find the different compounds
IDs <- distinct(pf$data, Image_Metadata_BROAD_ID)
dim(IDs)

```

## Distance of the data

Calculate the distance of the replicate for each compound.

```{r correlation}
start.time <- Sys.time()

# function to calculate the distance between two sets
distJaccard <- function(x, y){
  # 4 sets: 50 first and 50 lasts features
  x.sort <- sort(x)
  y.sort <- sort(y)
  A <- names(x.sort[1:50])
  B <- names(y.sort[1:50])
  C <- names(x.sort[-(1:50)])
  D <- names(y.sort[-(1:50)])
  d.top <- (length(union(A, B)) - length(intersect(A, B)))/length(union(A, B))
  d.bottom <- (length(union(C, D)) - length(intersect(C, D)))/length(union(C, D))
    
  return((d.top + d.bottom)/2)
}

comp.dist.median <- c()
# loop over all IDs
for (variable in IDs$Image_Metadata_BROAD_ID){
  #filtering to choose only for one compound
  comp <- filter(pf$data, Image_Metadata_BROAD_ID %in% variable)
  comp <- comp[,pf$feat_cols]
  
  # distance of the features
  comp.dist <- lapply(1:dim(comp)[1], function(x) (lapply(1:dim(comp)[1], function(y) return(distJaccard(comp[x,], comp[y,]))) %>%
    unlist)) %>% do.call(rbind, .)
  
  # median of the distances
  comp.dist.median <- c(comp.dist.median, median(comp.dist[lower.tri(comp.dist)],na.rm=TRUE))
}

hist(comp.dist.median,
     main="Histogram for Median Replicate Distance",
     xlab="Median Replicate Distance")


end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
```


## Thresholding of poor replicate distance

H0: median non replicate distance

The Null distribution is estimated by finding the median distance of non replicates. 
Select randomly 4 replicates each coming from a different compound and calculate the median distance. 
Repeat this N times to get a distribution.
Finally estimate a threshold (5th percentile) to filter out compounds with poor replicate distance.

```{r replicate distance}
start.time <- Sys.time()

# vector of the median of non replicate distance
random.replicate.dist.median <- c()

# loop over N times to get a distribution
for (i in 1:N){
  # group by IDs
  # sample fixed number per group -> choose 4 replicates randomly from different group
  random.replicate <- pf$data %>% group_by(Image_Metadata_BROAD_ID) %>% sample_n(1, replace = FALSE) %>% ungroup(random.replicate)
  random.replicate <- sample_n(random.replicate, 4, replace = FALSE)
  
  
  comp <- as.data.frame(random.replicate[,pf$feat_cols])
  
  # distance of the features
  comp.dist <- lapply(1:dim(comp)[1], function(x) (lapply(1:dim(comp)[1], function(y) return(distJaccard(comp[x,], comp[y,]))) %>%
    unlist)) %>% do.call(rbind, .)
  
  # median of the non replicate distance
  random.replicate.dist.median <- c(random.replicate.dist.median, median(comp.dist[lower.tri(comp.dist)],na.rm=TRUE))
  
}

# histogram plot
hist(random.replicate.dist.median,
     main="Histogram for Non Replicate Median Distance",
     xlab="Non Replicate Median Distance")

# threshold to determine if can reject H0
thres <- quantile(random.replicate.dist.median, .05)
print(thres)

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
```

## Hit Selection

Select strong replicate.

```{r Hit Selection}
# find indices of replicate median distance < threshold
inds <- which(comp.dist.median < thres)

# find values of the median that are hit selected
hit.select <- comp.dist.median[inds]

# find component that are hit selected
hit.select.IDs <- IDs$Image_Metadata_BROAD_ID[inds]

# ratio of strong median replicate correlation
high.median.dist <- length(hit.select)/length(comp.dist.median)
print(high.median.dist)

```


## Results

|  Method   | Pearson | Spearman | Kendall | Euclidean | Maximum | Manhattan | Distance based on Jaccard |
| --------- | ------- | -------- | ------- | --------- | ------- | --------- | ------------------------- |
| N = 1000  | 0.5819  | -------- | ------- | --------- | ------- | --------- |-------------------------- |
| N = 5000  | 0.5806  | 0.5519   | 0.5419  | 0.4606    | 0.3612  | 0.4875    | 0.6175                    |
| N = 10000 | 0.5850  | -------- | ------- | --------- | ------- | --------- |-------------------------- |


- Difference between Pearson and Spearman correlation seem not to be very significant (no statistical test was performed).
- Distance method compared to correlation metric gives a lower ratio of hit selection (more or less 10% lower).
- Distance based on Jaccard give the best result: but computationally more costly. Take (on amazone cluster) ~10min for the replicates part and ~40min for the non replicates part (for N = 5000)

TODO: optimize the code of the distance (i.e. parallelize, change sort, etc)

## Saving data

```{r output data}
# select high median correlation replicate 
pf$data <- filter(pf$data, Image_Metadata_BROAD_ID %in% hit.select.IDs)

saveRDS(pf, "../input/Pf_Gustafsdottir_hitSelection_distJ.rds")

```